{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[toc]\n",
    "\n",
    "# Word2vec SkipGram Pytorch 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T03:26:43.456980Z",
     "start_time": "2020-07-25T03:26:42.595078Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T03:26:43.462664Z",
     "start_time": "2020-07-25T03:26:43.459087Z"
    }
   },
   "outputs": [],
   "source": [
    "negative_sample_size = 100 # 负采样的个数\n",
    "window_size = 5 # 窗口宽度\n",
    "embedding_size = 100\n",
    "max_vocab_size = 30000\n",
    "\n",
    "n_epochs = 1\n",
    "batch_size = 128\n",
    "learning_rate = 0.05\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T03:26:46.931864Z",
     "start_time": "2020-07-25T03:26:43.464400Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = '/Users/ed/Downloads/text8/text8.train.txt'\n",
    "\n",
    "with open(file_path) as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = text.lower().split()\n",
    "\n",
    "vocab_dict = dict(Counter(text).most_common(max_vocab_size - 1))\n",
    "vocab_dict['UNK'] = len(text) - np.sum(list(vocab_dict.values()))\n",
    "\n",
    "word2idx = dict(zip(vocab_dict.keys(), range(len(vocab_dict))))\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T03:26:46.942240Z",
     "start_time": "2020-07-25T03:26:46.935120Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counts = np.array(list(vocab_dict.values()))\n",
    "word_freqs = word_counts / np.sum(word_counts)\n",
    "word_freqs = word_freqs ** (3 / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-25T03:26:42.598Z"
    }
   },
   "outputs": [],
   "source": [
    "class WordEmbeddingDataSet(Dataset):\n",
    "    def __init__(self, text, word2idx, idx2word, word_freqs, word_counts, negative_sample_size=5, window_size=2):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.text_encode = [word2idx.get(word, word2idx['UNK']) for word in text]\n",
    "        self.text_encode = torch.LongTensor(self.text_encode)\n",
    "\n",
    "        self.window_size = window_size\n",
    "        self.negative_sample_size = negative_sample_size\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.word_freqs = word_freqs\n",
    "        self.word_counts = torch.Tensor(word_counts)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_encode)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        center_words = self.text_encode[idx]\n",
    "        pos_indices = list(range(idx - self.window_size, idx)) + list(range(idx + 1, idx + 1 + self.window_size))\n",
    "        pos_indices = list(filter(lambda x: x < len(self.text_encode), pos_indices)) # 防止下标超出边界\n",
    "        pos_words = self.text_encode[pos_indices] \n",
    "        neg_words = torch.multinomial(self.word_counts, self.negative_sample_size * pos_words.shape[0],\n",
    "                                      replacement=True)\n",
    "        # 注意这三个都是 longTensor 类型的\n",
    "        # 以词为单位输出样本\n",
    "        return center_words, pos_words, neg_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-25T03:26:42.599Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = WordEmbeddingDataSet(text, word2idx, idx2word, word_freqs, word_counts, negative_sample_size, window_size)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-25T03:26:42.600Z"
    }
   },
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # 每个单词有两个 embedding\n",
    "        self.u_embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        self.v_embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "\n",
    "    def forward(self, input_labels, pos_labels, neg_labels):\n",
    "        center_embedding = self.u_embedding(input_labels)\n",
    "        pos_embedding = self.v_embedding(pos_labels)\n",
    "        neg_embedding = self.v_embedding(neg_labels)\n",
    "\n",
    "        center_embedding = center_embedding.unsqueeze(2)\n",
    "        pos_dot = torch.bmm(pos_embedding, center_embedding)\n",
    "        pos_dot = pos_dot.squeeze(2)\n",
    "\n",
    "        neg_dot = torch.bmm(neg_embedding, -center_embedding)\n",
    "        neg_dot = neg_dot.squeeze(2)\n",
    "\n",
    "        log_pos = F.logsigmoid(pos_dot).sum(axis=1)\n",
    "        log_neg = F.logsigmoid(neg_dot).sum(axis=1)\n",
    "        loss = (log_pos + log_neg).mean()\n",
    "\n",
    "        return -loss\n",
    "\n",
    "    def input_embedding(self):\n",
    "        return self.u_embedding.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-25T03:26:42.601Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SkipGram(vocab_size=max_vocab_size, embedding_size=embedding_size)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-25T03:26:42.603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1 Step: 500 Loss: 152.97000122070312 time_used: 240.0837619304657\n",
      "Model saved successfully!\n",
      "Epoch: 0/1 Step: 1000 Loss: 181.14987182617188 time_used: 228.9447259902954\n",
      "Model saved successfully!\n",
      "Epoch: 0/1 Step: 1500 Loss: 152.96710205078125 time_used: 236.4238359928131\n",
      "Model saved successfully!\n",
      "Epoch: 0/1 Step: 2000 Loss: 105.79800415039062 time_used: 231.19964408874512\n",
      "Model saved successfully!\n",
      "Epoch: 0/1 Step: 2500 Loss: 163.25140380859375 time_used: 246.37053894996643\n",
      "Model saved successfully!\n",
      "Epoch: 0/1 Step: 3000 Loss: 98.78641510009766 time_used: 263.79660415649414\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "while epoch < n_epochs:\n",
    "    time_start = time.time()\n",
    "    for i, (input_labels, pos_labels, neg_labels) in enumerate(dataloader, start=1):\n",
    "        input_labels = input_labels.to(device)\n",
    "        pos_labels = pos_labels.to(device)\n",
    "        neg_labels = neg_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_labels, pos_labels, neg_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(\"Epoch: {}/{} Step: {} Loss: {} time_used: {}\".format(epoch, n_epochs, i, loss.item(),\n",
    "                                                                        time.time() - time_start))\n",
    "            time_start = time.time()\n",
    "            for file in os.listdir():\n",
    "                if file.endswith(\"pth\"):\n",
    "                    os.remove(file)\n",
    "            torch.save(model.state_dict(), \"embedding-{}.pth\".format(i))\n",
    "            print(\"Model saved successfully!\")\n",
    "    epoch += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-25T03:26:42.604Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"embedding-14500.pth\"))\n",
    "embedding_weights = model.input_embedding()\n",
    "\n",
    "def find_nearest(word):\n",
    "    index = word2idx[word]\n",
    "    embedding = embedding_weights[index]\n",
    "    cos_dis = cosine_distances(embedding.reshape(1, -1), embedding_weights).squeeze()\n",
    "    return [idx2word[i] for i in cos_dis.argsort()[:10]]\n",
    "\n",
    "\n",
    "for word in [\"two\", \"america\", \"computer\"]:\n",
    "    print(word, find_nearest(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [PyTorch实现Word2Vec - mathor](https://wmathor.com/index.php/archives/1435/)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2]",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
